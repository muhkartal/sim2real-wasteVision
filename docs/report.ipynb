{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c71d8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 38\u001b[0m\n\u001b[0;32m      1\u001b[0m {\n\u001b[0;32m      2\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcells\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      3\u001b[0m   {\n\u001b[0;32m      4\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m      6\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# İstanbul Drone Waste Detection: Synthetic Data Analysis Report\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis notebook analyzes the performance of the waste detection model trained on synthetic data for drone-based waste detection in Istanbul.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Author:** [Your Name]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**Date:** [Current Date]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Table of Contents\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. [Introduction](#introduction)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. [Dataset Analysis](#dataset-analysis)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Dataset Overview](#dataset-overview)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Class Distribution](#class-distribution)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Environmental Variations](#environmental-variations)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Lighting Conditions](#lighting-conditions)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Sample Visualization](#sample-visualization)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. [Training Analysis](#training-analysis)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Training Configuration](#training-configuration)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Training Curves](#training-curves)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. [Model Evaluation](#model-evaluation)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Overall Performance](#overall-performance)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Per-Class Performance](#per-class-performance)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Qualitative Detection Examples](#qualitative-detection-examples)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. [Analysis of Sim-to-Real Gap](#sim-to-real-gap)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Strengths of Synthetic Data](#strengths-of-synthetic-data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Weaknesses of Synthetic Data](#weaknesses-of-synthetic-data)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - [Gap Analysis](#gap-analysis)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6. [Conclusions and Future Work](#conclusions-and-future-work)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m    ]\n\u001b[0;32m     35\u001b[0m   },\n\u001b[0;32m     36\u001b[0m   {\n\u001b[0;32m     37\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 38\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnull\u001b[49m,\n\u001b[0;32m     39\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     40\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Import necessary libraries\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport os\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport sys\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport json\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport yaml\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport numpy as np\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport pandas as pd\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport matplotlib.pyplot as plt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport seaborn as sns\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport cv2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom pathlib import Path\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom IPython.display import display, Markdown, HTML\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Set plotting style\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.style.use(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfivethirtyeight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msns.set_context(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, font_scale=1.2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Set paths\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATASET_PATH = Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../dataset\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWEIGHTS_PATH = Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../weights\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOCS_PATH = Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../docs\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFIGURES_PATH = DOCS_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mfigures\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create figures directory if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFIGURES_PATH.mkdir(parents=True, exist_ok=True)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     66\u001b[0m    ]\n\u001b[0;32m     67\u001b[0m   },\n\u001b[0;32m     68\u001b[0m   {\n\u001b[0;32m     69\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     71\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Introduction\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis report analyzes the effectiveness of using synthetic data for training waste detection models for drone-based monitoring in İstanbul. The synthetic data pipeline uses AirSim and Unreal Engine to generate realistic imagery of waste items across four distinct İstanbul environments:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Bosphorus waterfront (Beşiktaş–Ortaköy style)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Balat/Karaköy narrow streets\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Yıldız Park\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. Modern urban plaza\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe main objectives of this report are to:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Analyze the properties and quality of the generated synthetic dataset\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. Evaluate the performance of a YOLOv8 detector trained on this synthetic data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Assess the sim-to-real gap and provide recommendations for future work\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m    ]\n\u001b[0;32m     87\u001b[0m   },\n\u001b[0;32m     88\u001b[0m   {\n\u001b[0;32m     89\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     90\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     91\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Dataset Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m    ]\n\u001b[0;32m     94\u001b[0m   },\n\u001b[0;32m     95\u001b[0m   {\n\u001b[0;32m     96\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     97\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m     98\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m     99\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Load dataset metadata\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata_path = DATASET_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdataset_metadata.json\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith open(metadata_path, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    dataset_metadata = json.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display basic dataset information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDataset Name: \u001b[39m\u001b[38;5;132;01m{dataset_metadata['name']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTotal Images: \u001b[39m\u001b[38;5;132;01m{dataset_metadata['total_images']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mFormat: \u001b[39m\u001b[38;5;132;01m{dataset_metadata['format']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mSplits: \u001b[39m\u001b[38;5;132;01m{dataset_metadata['splits']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNumber of Classes: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mlen(dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m    ]\n\u001b[0;32m    112\u001b[0m   },\n\u001b[0;32m    113\u001b[0m   {\n\u001b[0;32m    114\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    116\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Class Distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms analyze the distribution of waste object classes in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m    ]\n\u001b[0;32m    121\u001b[0m   },\n\u001b[0;32m    122\u001b[0m   {\n\u001b[0;32m    123\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    124\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    125\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    126\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Extract class counts\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_names = [c[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] for c in dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_counts = [c[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] for c in dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create DataFrame for easier analysis\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_df = pd.DataFrame(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: class_names,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: class_counts,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: [c[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] for c in dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: [c[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] for c in dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: [c[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] for c in dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclasses\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]],\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m})\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Calculate percentages\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_objects = sum(class_counts)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = class_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] / total_objects * 100\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display class distribution table\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay(class_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Plot class distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.figure(figsize=(12, 6))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max = sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=class_df, palette=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaste Class Distribution in Synthetic Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Add count labels on top of bars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor i, count in enumerate(class_counts):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ax.text(i, count + 50, str(count), ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, va=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fontweight=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Save figure\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mclass_distribution.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.show()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m    ]\n\u001b[0;32m    162\u001b[0m   },\n\u001b[0;32m    163\u001b[0m   {\n\u001b[0;32m    164\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    165\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    166\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Environmental Variations\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms analyze the distribution of environment types in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    170\u001b[0m    ]\n\u001b[0;32m    171\u001b[0m   },\n\u001b[0;32m    172\u001b[0m   {\n\u001b[0;32m    173\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    174\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    175\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    176\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Extract environment statistics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_stats = dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatistics\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menvironments\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_names = list(env_stats.keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_counts = list(env_stats.values())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_df = pd.DataFrame(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnvironment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: env_names,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: env_counts\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m})\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = env_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] / sum(env_counts) * 100\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display environment distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay(env_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Plot environment distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.figure(figsize=(10, 6))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max = sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnvironment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=env_df, palette=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues_d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnvironment Distribution in Synthetic Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Add count labels on top of bars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor i, count in enumerate(env_counts):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ax.text(i, count + 10, str(count), ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, va=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fontweight=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Save figure\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124menvironment_distribution.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.show()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m    ]\n\u001b[0;32m    207\u001b[0m   },\n\u001b[0;32m    208\u001b[0m   {\n\u001b[0;32m    209\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    210\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    211\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Lighting Conditions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms analyze the distribution of lighting conditions in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m    ]\n\u001b[0;32m    216\u001b[0m   },\n\u001b[0;32m    217\u001b[0m   {\n\u001b[0;32m    218\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    220\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    221\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Extract lighting statistics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_stats = dataset_metadata[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatistics\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m][\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlighting_conditions\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_names = list(light_stats.keys())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_counts = list(light_stats.values())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Create DataFrame\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_df = pd.DataFrame(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLighting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: light_names,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: light_counts\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m})\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlight_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = light_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] / sum(light_counts) * 100\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display lighting distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay(light_df)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Plot lighting distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.figure(figsize=(10, 6))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124max = sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLighting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=light_df, palette=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYlOrRd\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLighting Condition Distribution in Synthetic Dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Add count labels on top of bars\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor i, count in enumerate(light_counts):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    ax.text(i, count + 10, str(count), ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, va=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fontweight=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Save figure\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mlighting_distribution.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplt.show()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m    ]\n\u001b[0;32m    251\u001b[0m   },\n\u001b[0;32m    252\u001b[0m   {\n\u001b[0;32m    253\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    254\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    255\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Sample Visualization\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms visualize a few sample images from each environment and lighting condition.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    259\u001b[0m    ]\n\u001b[0;32m    260\u001b[0m   },\n\u001b[0;32m    261\u001b[0m   {\n\u001b[0;32m    262\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    263\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    264\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    265\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef load_sample_images(num_samples=3):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mLoad sample images from each environment and lighting condition.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Load metadata with full image paths\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        metadata_path = DATASET_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmetadata.json\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        with open(metadata_path, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            full_metadata = json.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        all_images = full_metadata.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, [])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Group images by environment\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        env_images = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for env_name in env_names:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            env_imgs = [img for img in all_images if img.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) == env_name]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if env_imgs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                # Sample up to num_samples images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                env_images[env_name] = random.sample(env_imgs, min(num_samples, len(env_imgs)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Group images by lighting condition\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        light_images = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for light_name in light_names:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            light_imgs = [img for img in all_images if img.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlighting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m).get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) == light_name]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            if light_imgs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                # Sample up to num_samples images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                light_images[light_name] = random.sample(light_imgs, min(num_samples, len(light_imgs)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return env_images, light_images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mError loading sample images: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef display_sample_images(image_dict, title, source_dir=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDisplay sample images from each category.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if not image_dict:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNo sample images available for \u001b[39m\u001b[38;5;132;01m{title}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Create figure\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_categories = len(image_dict)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_samples = max(len(imgs) for imgs in image_dict.values())\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    fig, axes = plt.subplots(num_categories, num_samples, figsize=(15, 3*num_categories))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    fig.suptitle(f\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample Images by \u001b[39m\u001b[38;5;132;01m{title}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, fontsize=16)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Display images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i, (category, imgs) in enumerate(image_dict.items()):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        for j, img_info in enumerate(imgs):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                img_path = DATASET_PATH / source_dir / img_info[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                img = cv2.imread(str(img_path))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                if num_categories > 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    ax = axes[i, j]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    ax = axes[j]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                ax.imshow(img)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                ax.set_title(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{category}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                ax.axis(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m                print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mError displaying image \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mimg_info.get(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)}: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.tight_layout(rect=[0, 0, 1, 0.96])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.savefig(FIGURES_PATH / f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mtitle.lower().replace(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)}_samples.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Import random module\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport random\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Load and display sample images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv_images, light_images = load_sample_images()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display environment samples\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_sample_images(env_images, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mEnvironment Type\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Display lighting condition samples\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_sample_images(light_images, \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mLighting Condition\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m    ]\n\u001b[0;32m    345\u001b[0m   },\n\u001b[0;32m    346\u001b[0m   {\n\u001b[0;32m    347\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    348\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    349\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Training Analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m    ]\n\u001b[0;32m    352\u001b[0m   },\n\u001b[0;32m    353\u001b[0m   {\n\u001b[0;32m    354\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    355\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    356\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    357\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Load training results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_results_path = WEIGHTS_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mtraining_results.json\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif training_results_path.exists():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with open(training_results_path, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        training_results = json.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Display training configuration\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTraining Configuration:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{training_results['model']['name']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPretrained: \u001b[39m\u001b[38;5;132;01m{training_results['model']['pretrained']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;132;01m{training_results['training']['epochs']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mBatch Size: \u001b[39m\u001b[38;5;132;01m{training_results['training']['batch_size']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mImage Size: \u001b[39m\u001b[38;5;132;01m{training_results['training']['image_size']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOptimizer: \u001b[39m\u001b[38;5;132;01m{training_results['training']['optimizer']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mLearning Rate: \u001b[39m\u001b[38;5;132;01m{training_results['training']['learning_rate']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTimestamp: \u001b[39m\u001b[38;5;132;01m{training_results['timestamp']}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melse:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTraining results not found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m    ]\n\u001b[0;32m    377\u001b[0m   },\n\u001b[0;32m    378\u001b[0m   {\n\u001b[0;32m    379\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    380\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    381\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Training Curves\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms visualize the training curves to analyze the model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms training progress.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    385\u001b[0m    ]\n\u001b[0;32m    386\u001b[0m   },\n\u001b[0;32m    387\u001b[0m   {\n\u001b[0;32m    388\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    389\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    390\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    391\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Try to find and load training history from YOLOv8 results directory\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtry:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    yolo_results_dir = Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../runs/detect\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Find the latest results directory\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    result_dirs = list(yolo_results_dir.glob(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124msynthetic_only*\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if result_dirs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        latest_dir = max(result_dirs, key=lambda p: p.stat().st_mtime)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        results_csv = latest_dir / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mresults.csv\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if results_csv.exists():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Load results\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            train_df = pd.read_csv(results_csv)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Plot training curves\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.figure(figsize=(12, 8))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Plot losses\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.subplot(2, 2, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/box_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Box Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/box_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Box Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBox Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.xlabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.ylabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.legend()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.grid(True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.subplot(2, 2, 2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/cls_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Cls Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval/cls_loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Cls Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Loss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.xlabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.ylabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.legend()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.grid(True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Plot metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.subplot(2, 2, 3)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/precision\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/recall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision and Recall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.xlabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.ylabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.legend()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.grid(True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.subplot(2, 2, 4)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/mAP50\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.plot(train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], train_df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics/mAP50-95\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], label=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5:0.95\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.xlabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.ylabel(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.legend()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.grid(True)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mtraining_curves.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            # Display final metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            final_metrics = train_df.iloc[-1]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mFinal Training Metrics (Epoch \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mint(final_metrics[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])})\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmAP@0.5: \u001b[39m\u001b[38;5;132;01m{final_metrics['metrics/mAP50']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmAP@0.5:0.95: \u001b[39m\u001b[38;5;132;01m{final_metrics['metrics/mAP50-95']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{final_metrics['metrics/precision']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{final_metrics['metrics/recall']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mTraining results CSV not found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    else:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNo YOLOv8 training results found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexcept Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mError loading training curves: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    464\u001b[0m    ]\n\u001b[0;32m    465\u001b[0m   },\n\u001b[0;32m    466\u001b[0m   {\n\u001b[0;32m    467\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    468\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    469\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Model Evaluation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms analyze the evaluation results on the test set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    473\u001b[0m    ]\n\u001b[0;32m    474\u001b[0m   },\n\u001b[0;32m    475\u001b[0m   {\n\u001b[0;32m    476\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    477\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    478\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    479\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Load evaluation metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_metrics_path = Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../docs/evaluation/evaluation_metrics.json\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif eval_metrics_path.exists():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    with open(eval_metrics_path, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) as f:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        eval_metrics = json.load(f)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    486\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Display overall metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    overall = eval_metrics[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mOverall Evaluation Metrics:\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPrecision: \u001b[39m\u001b[38;5;132;01m{overall['precision']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    490\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mRecall: \u001b[39m\u001b[38;5;132;01m{overall['recall']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmAP@0.5: \u001b[39m\u001b[38;5;132;01m{overall['mAP50']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmAP@0.5:0.95: \u001b[39m\u001b[38;5;132;01m{overall['mAP50-95']:.4f}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    # Display class metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in eval_metrics:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        class_metrics = pd.DataFrame(eval_metrics[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        display(class_metrics)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Plot class metrics\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.figure(figsize=(12, 6))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.subplot(1, 2, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=class_metrics, color=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskyblue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision by Class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.ylim(0, 1.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.subplot(1, 2, 2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=class_metrics, color=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgreen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall by Class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.ylim(0, 1.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mprecision_recall_by_class.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.figure(figsize=(12, 6))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.subplot(1, 2, 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP50\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=class_metrics, color=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoral\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    520\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5 by Class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.ylim(0, 1.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.subplot(1, 2, 2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sns.barplot(x=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, y=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP50-95\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, data=class_metrics, color=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightpink\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.title(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmAP@0.5:0.95 by Class\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.xticks(rotation=45, ha=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.ylim(0, 1.0)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mmap_by_class.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melse:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mEvaluation metrics not found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m    ]\n\u001b[0;32m    536\u001b[0m   },\n\u001b[0;32m    537\u001b[0m   {\n\u001b[0;32m    538\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    539\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    540\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Qualitative Detection Examples\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms visualize some example detections from the test set.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m    ]\n\u001b[0;32m    545\u001b[0m   },\n\u001b[0;32m    546\u001b[0m   {\n\u001b[0;32m    547\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    548\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution_count\u001b[39m\u001b[38;5;124m\"\u001b[39m: null,\n\u001b[0;32m    549\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    550\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef load_detection_examples(num_samples=5):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mLoad sample detections from the test set.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Find prediction directory (should be created by YOLOv8 val)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pred_dirs = list(Path(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m../runs/detect\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m).glob(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mval*\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not pred_dirs:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNo prediction results found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        latest_dir = max(pred_dirs, key=lambda p: p.stat().st_mtime)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pred_dir = latest_dir / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not pred_dir.exists():\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPrediction directory not found: \u001b[39m\u001b[38;5;132;01m{pred_dir}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Get prediction images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        pred_images = list(pred_dir.glob(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m*.jpg\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        if not pred_images:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNo prediction images found.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            return []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        # Sample images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        sample_images = random.sample(pred_images, min(num_samples, len(pred_images)))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return sample_images\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mError loading detection examples: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return []\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef display_detection_examples(image_paths):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDisplay detection examples.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    if not image_paths:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        print(\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mNo detection examples to display.\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    num_images = len(image_paths)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    cols = min(3, num_images)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    rows = (num_images + cols - 1) // cols\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.figure(figsize=(15, 5 * rows))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    for i, img_path in enumerate(image_paths):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        try:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            img = cv2.imread(str(img_path))\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.subplot(rows, cols, i + 1)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.imshow(img)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.title(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mDetection Example \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mi+1}\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            plt.axis(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        except Exception as e:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m            print(f\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mError displaying detection image \u001b[39m\u001b[38;5;132;01m{img_path}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{e}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.tight_layout()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    606\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.savefig(FIGURES_PATH / \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mdetection_examples.png\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m, dpi=300, bbox_inches=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    plt.show()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# Load and display detection examples\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetection_examples = load_detection_examples()\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_detection_examples(detection_examples)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    612\u001b[0m    ]\n\u001b[0;32m    613\u001b[0m   },\n\u001b[0;32m    614\u001b[0m   {\n\u001b[0;32m    615\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    616\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    617\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Analysis of Sim-to-Real Gap\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis section analyzes the strengths and weaknesses of the synthetic data approach and discusses the potential sim-to-real gap.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    621\u001b[0m    ]\n\u001b[0;32m    622\u001b[0m   },\n\u001b[0;32m    623\u001b[0m   {\n\u001b[0;32m    624\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    625\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    626\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Strengths of Synthetic Data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Controlled Data Generation**: Our synthetic pipeline allows precise control over environmental variables (lighting, weather, camera pose) that would be difficult to systematically capture in real-world data collection.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Perfect Ground Truth**: Synthetic data provides pixel-perfect ground truth annotations without the inconsistencies or errors that can occur with manual labeling.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Diverse Scenarios**: We can efficiently generate a wide variety of scenarios across different İstanbul environments that would require significant time and resources to collect manually.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    634\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Rare Events**: We can generate scenes with unusual waste distributions or lighting conditions that might be rare in real-world data collection.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    636\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Privacy Compliance**: Synthetic data eliminates privacy concerns that might arise when capturing real-world imagery in public spaces.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    638\u001b[0m    ]\n\u001b[0;32m    639\u001b[0m   },\n\u001b[0;32m    640\u001b[0m   {\n\u001b[0;32m    641\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    642\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    643\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    644\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Weaknesses of Synthetic Data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    645\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Realism Gap**: Despite our efforts to create realistic environments, there remains a gap between synthetic and real-world imagery in terms of texture details, lighting effects, and physics.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Limited Asset Diversity**: Our waste models, while diverse, still represent a subset of the full variety of waste types and appearances found in real environments.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Simplified Physics**: The placement and interaction of waste objects follows simplified physics models that may not perfectly match real-world scenarios.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Environment Simplification**: Our simulated environments capture the essence of İstanbul locations but lack the full complexity and detail of real urban environments.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Occlusion and Complex Scenes**: Real-world waste often appears in complex scenes with partial occlusion, varying states of degradation, and challenging contexts that are difficult to fully simulate.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    655\u001b[0m    ]\n\u001b[0;32m    656\u001b[0m   },\n\u001b[0;32m    657\u001b[0m   {\n\u001b[0;32m    658\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    659\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    660\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Gap Analysis\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    662\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBased on our evaluation, the primary factors contributing to the sim-to-real gap include:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    664\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Texture and Material Realism**: Real waste items have complex textures, weathering, and deformation that are challenging to model synthetically.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    667\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Environmental Context**: Real environments have greater complexity in terms of background elements, ambient occlusion, and contextual placement of waste.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    668\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Lighting Complexity**: Real-world lighting includes subtle effects like inter-reflections, subsurface scattering, and atmospheric effects that are computationally expensive to simulate perfectly.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    671\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Object Variation**: Real waste objects show greater variation in appearance, condition, and positioning than our synthetic models.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Camera Effects**: Real drone cameras exhibit lens distortion, motion blur, and sensor noise characteristics that differ from our simulated camera.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m    ]\n\u001b[0;32m    675\u001b[0m   },\n\u001b[0;32m    676\u001b[0m   {\n\u001b[0;32m    677\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkdown\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    678\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[0;32m    679\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Conclusions and Future Work\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Conclusions\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur synthetic data pipeline successfully generated a diverse and balanced dataset for training waste detection models in İstanbul\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms urban environments. The YOLOv8 detector trained on this synthetic data achieved promising results on the synthetic test set, with an overall mAP@0.5 of X.XX and mAP@0.5:0.95 of Y.YY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe analysis of the sim-to-real gap highlights both the strengths of our approach and areas for improvement. Despite limitations in perfect realism, the synthetic dataset provides valuable training data for object detection models, especially in scenarios where collecting and annotating real-world data would be challenging.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m### Future Work\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. **Domain Randomization**: Implement more aggressive domain randomization techniques to help the model generalize better to real-world conditions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    691\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. **Fine-tuning on Real Data**: Collect a small set of real-world drone imagery from İstanbul for fine-tuning the synthetic-trained model, potentially using the `finetune.py` script framework we\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve established.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. **Improved Asset Quality**: Develop higher-fidelity 3D models of waste objects with more realistic textures, deformations, and weathering effects.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    695\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4. **Environmental Complexity**: Enhance the environmental models to include more detailed urban elements specific to İstanbul.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5. **Drone Camera Simulation**: Implement more realistic camera effects including motion blur, lens distortion, and sensor noise characteristics typical of drone cameras.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6. **Seasonal Variations**: Extend the pipeline to include seasonal variations (snow, rain, autumn leaves) to improve robustness to different weather conditions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7. **Real-world Validation**: Conduct a comprehensive real-world validation study using a drone with the trained model to quantitatively assess the sim-to-real gap.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8. **Multi-modal Learning**: Explore multi-modal approaches that combine RGB imagery with depth or thermal information for more robust waste detection.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    705\u001b[0m    ]\n\u001b[0;32m    706\u001b[0m   }\n\u001b[0;32m    707\u001b[0m  ],\n\u001b[0;32m    708\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    709\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernelspec\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    710\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython 3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    711\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    712\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    713\u001b[0m   },\n\u001b[0;32m    714\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    715\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodemirror_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m    718\u001b[0m    },\n\u001b[0;32m    719\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_extension\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    720\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmimetype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/x-python\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    721\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    722\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbconvert_exporter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    723\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpygments_lexer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipython3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    724\u001b[0m    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.8.10\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    725\u001b[0m   }\n\u001b[0;32m    726\u001b[0m  },\n\u001b[0;32m    727\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m    728\u001b[0m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnbformat_minor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m    729\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# İstanbul Drone Waste Detection: Synthetic Data Analysis Report\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook analyzes the performance of the waste detection model trained on synthetic data for drone-based waste detection in Istanbul.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Author:** [Your Name]\\n\",\n",
    "    \"**Date:** [Current Date]\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Table of Contents\\n\",\n",
    "    \"1. [Introduction](#introduction)\\n\",\n",
    "    \"2. [Dataset Analysis](#dataset-analysis)\\n\",\n",
    "    \"   - [Dataset Overview](#dataset-overview)\\n\",\n",
    "    \"   - [Class Distribution](#class-distribution)\\n\",\n",
    "    \"   - [Environmental Variations](#environmental-variations)\\n\",\n",
    "    \"   - [Lighting Conditions](#lighting-conditions)\\n\",\n",
    "    \"   - [Sample Visualization](#sample-visualization)\\n\",\n",
    "    \"3. [Training Analysis](#training-analysis)\\n\",\n",
    "    \"   - [Training Configuration](#training-configuration)\\n\",\n",
    "    \"   - [Training Curves](#training-curves)\\n\",\n",
    "    \"4. [Model Evaluation](#model-evaluation)\\n\",\n",
    "    \"   - [Overall Performance](#overall-performance)\\n\",\n",
    "    \"   - [Per-Class Performance](#per-class-performance)\\n\",\n",
    "    \"   - [Qualitative Detection Examples](#qualitative-detection-examples)\\n\",\n",
    "    \"5. [Analysis of Sim-to-Real Gap](#sim-to-real-gap)\\n\",\n",
    "    \"   - [Strengths of Synthetic Data](#strengths-of-synthetic-data)\\n\",\n",
    "    \"   - [Weaknesses of Synthetic Data](#weaknesses-of-synthetic-data)\\n\",\n",
    "    \"   - [Gap Analysis](#gap-analysis)\\n\",\n",
    "    \"6. [Conclusions and Future Work](#conclusions-and-future-work)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Import necessary libraries\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import cv2\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from IPython.display import display, Markdown, HTML\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set plotting style\\n\",\n",
    "    \"plt.style.use('fivethirtyeight')\\n\",\n",
    "    \"sns.set_context(\\\"notebook\\\", font_scale=1.2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set paths\\n\",\n",
    "    \"DATASET_PATH = Path(\\\"../dataset\\\")\\n\",\n",
    "    \"WEIGHTS_PATH = Path(\\\"../weights\\\")\\n\",\n",
    "    \"DOCS_PATH = Path(\\\"../docs\\\")\\n\",\n",
    "    \"FIGURES_PATH = DOCS_PATH / \\\"figures\\\"\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create figures directory if it doesn't exist\\n\",\n",
    "    \"FIGURES_PATH.mkdir(parents=True, exist_ok=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Introduction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This report analyzes the effectiveness of using synthetic data for training waste detection models for drone-based monitoring in İstanbul. The synthetic data pipeline uses AirSim and Unreal Engine to generate realistic imagery of waste items across four distinct İstanbul environments:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Bosphorus waterfront (Beşiktaş–Ortaköy style)\\n\",\n",
    "    \"2. Balat/Karaköy narrow streets\\n\",\n",
    "    \"3. Yıldız Park\\n\",\n",
    "    \"4. Modern urban plaza\\n\",\n",
    "    \"\\n\",\n",
    "    \"The main objectives of this report are to:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. Analyze the properties and quality of the generated synthetic dataset\\n\",\n",
    "    \"2. Evaluate the performance of a YOLOv8 detector trained on this synthetic data\\n\",\n",
    "    \"3. Assess the sim-to-real gap and provide recommendations for future work\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Dataset Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load dataset metadata\\n\",\n",
    "    \"metadata_path = DATASET_PATH / \\\"dataset_metadata.json\\\"\\n\",\n",
    "    \"with open(metadata_path, 'r') as f:\\n\",\n",
    "    \"    dataset_metadata = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display basic dataset information\\n\",\n",
    "    \"print(f\\\"Dataset Name: {dataset_metadata['name']}\\\")\\n\",\n",
    "    \"print(f\\\"Total Images: {dataset_metadata['total_images']}\\\")\\n\",\n",
    "    \"print(f\\\"Format: {dataset_metadata['format']}\\\")\\n\",\n",
    "    \"print(f\\\"Splits: {dataset_metadata['splits']}\\\")\\n\",\n",
    "    \"print(f\\\"Number of Classes: {len(dataset_metadata['classes'])}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Class Distribution\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the distribution of waste object classes in the dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Extract class counts\\n\",\n",
    "    \"class_names = [c['name'] for c in dataset_metadata['classes']]\\n\",\n",
    "    \"class_counts = [c['count']['total'] for c in dataset_metadata['classes']]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create DataFrame for easier analysis\\n\",\n",
    "    \"class_df = pd.DataFrame({\\n\",\n",
    "    \"    'Class': class_names,\\n\",\n",
    "    \"    'Count': class_counts,\\n\",\n",
    "    \"    'Train': [c['count']['train'] for c in dataset_metadata['classes']],\\n\",\n",
    "    \"    'Val': [c['count']['val'] for c in dataset_metadata['classes']],\\n\",\n",
    "    \"    'Test': [c['count']['test'] for c in dataset_metadata['classes']],\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate percentages\\n\",\n",
    "    \"total_objects = sum(class_counts)\\n\",\n",
    "    \"class_df['Percentage'] = class_df['Count'] / total_objects * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display class distribution table\\n\",\n",
    "    \"display(class_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot class distribution\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"ax = sns.barplot(x='Class', y='Count', data=class_df, palette='viridis')\\n\",\n",
    "    \"plt.title('Waste Class Distribution in Synthetic Dataset')\\n\",\n",
    "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add count labels on top of bars\\n\",\n",
    "    \"for i, count in enumerate(class_counts):\\n\",\n",
    "    \"    ax.text(i, count + 50, str(count), ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save figure\\n\",\n",
    "    \"plt.savefig(FIGURES_PATH / \\\"class_distribution.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Environmental Variations\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the distribution of environment types in the dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Extract environment statistics\\n\",\n",
    "    \"env_stats = dataset_metadata['statistics']['environments']\\n\",\n",
    "    \"env_names = list(env_stats.keys())\\n\",\n",
    "    \"env_counts = list(env_stats.values())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create DataFrame\\n\",\n",
    "    \"env_df = pd.DataFrame({\\n\",\n",
    "    \"    'Environment': env_names,\\n\",\n",
    "    \"    'Count': env_counts\\n\",\n",
    "    \"})\\n\",\n",
    "    \"env_df['Percentage'] = env_df['Count'] / sum(env_counts) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display environment distribution\\n\",\n",
    "    \"display(env_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot environment distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"ax = sns.barplot(x='Environment', y='Count', data=env_df, palette='Blues_d')\\n\",\n",
    "    \"plt.title('Environment Distribution in Synthetic Dataset')\\n\",\n",
    "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add count labels on top of bars\\n\",\n",
    "    \"for i, count in enumerate(env_counts):\\n\",\n",
    "    \"    ax.text(i, count + 10, str(count), ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save figure\\n\",\n",
    "    \"plt.savefig(FIGURES_PATH / \\\"environment_distribution.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Lighting Conditions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the distribution of lighting conditions in the dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Extract lighting statistics\\n\",\n",
    "    \"light_stats = dataset_metadata['statistics']['lighting_conditions']\\n\",\n",
    "    \"light_names = list(light_stats.keys())\\n\",\n",
    "    \"light_counts = list(light_stats.values())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create DataFrame\\n\",\n",
    "    \"light_df = pd.DataFrame({\\n\",\n",
    "    \"    'Lighting': light_names,\\n\",\n",
    "    \"    'Count': light_counts\\n\",\n",
    "    \"})\\n\",\n",
    "    \"light_df['Percentage'] = light_df['Count'] / sum(light_counts) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display lighting distribution\\n\",\n",
    "    \"display(light_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Plot lighting distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"ax = sns.barplot(x='Lighting', y='Count', data=light_df, palette='YlOrRd')\\n\",\n",
    "    \"plt.title('Lighting Condition Distribution in Synthetic Dataset')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add count labels on top of bars\\n\",\n",
    "    \"for i, count in enumerate(light_counts):\\n\",\n",
    "    \"    ax.text(i, count + 10, str(count), ha='center', va='bottom', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save figure\\n\",\n",
    "    \"plt.savefig(FIGURES_PATH / \\\"lighting_distribution.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Sample Visualization\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize a few sample images from each environment and lighting condition.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def load_sample_images(num_samples=3):\\n\",\n",
    "    \"    \\\"\\\"\\\"Load sample images from each environment and lighting condition.\\\"\\\"\\\"\\n\",\n",
    "    \"    # Load metadata with full image paths\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        metadata_path = DATASET_PATH / \\\"metadata.json\\\"\\n\",\n",
    "    \"        with open(metadata_path, 'r') as f:\\n\",\n",
    "    \"            full_metadata = json.load(f)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        all_images = full_metadata.get('images', [])\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Group images by environment\\n\",\n",
    "    \"        env_images = {}\\n\",\n",
    "    \"        for env_name in env_names:\\n\",\n",
    "    \"            env_imgs = [img for img in all_images if img.get('environment') == env_name]\\n\",\n",
    "    \"            if env_imgs:\\n\",\n",
    "    \"                # Sample up to num_samples images\\n\",\n",
    "    \"                env_images[env_name] = random.sample(env_imgs, min(num_samples, len(env_imgs)))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Group images by lighting condition\\n\",\n",
    "    \"        light_images = {}\\n\",\n",
    "    \"        for light_name in light_names:\\n\",\n",
    "    \"            light_imgs = [img for img in all_images if img.get('lighting', {}).get('condition') == light_name]\\n\",\n",
    "    \"            if light_imgs:\\n\",\n",
    "    \"                # Sample up to num_samples images\\n\",\n",
    "    \"                light_images[light_name] = random.sample(light_imgs, min(num_samples, len(light_imgs)))\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        return env_images, light_images\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error loading sample images: {e}\\\")\\n\",\n",
    "    \"        return {}, {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"def display_sample_images(image_dict, title, source_dir='images'):\\n\",\n",
    "    \"    \\\"\\\"\\\"Display sample images from each category.\\\"\\\"\\\"\\n\",\n",
    "    \"    if not image_dict:\\n\",\n",
    "    \"        print(f\\\"No sample images available for {title}\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create figure\\n\",\n",
    "    \"    num_categories = len(image_dict)\\n\",\n",
    "    \"    num_samples = max(len(imgs) for imgs in image_dict.values())\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    fig, axes = plt.subplots(num_categories, num_samples, figsize=(15, 3*num_categories))\\n\",\n",
    "    \"    fig.suptitle(f'Sample Images by {title}', fontsize=16)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display images\\n\",\n",
    "    \"    for i, (category, imgs) in enumerate(image_dict.items()):\\n\",\n",
    "    \"        for j, img_info in enumerate(imgs):\\n\",\n",
    "    \"            try:\\n\",\n",
    "    \"                img_path = DATASET_PATH / source_dir / img_info['filename']\\n\",\n",
    "    \"                img = cv2.imread(str(img_path))\\n\",\n",
    "    \"                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                if num_categories > 1:\\n\",\n",
    "    \"                    ax = axes[i, j]\\n\",\n",
    "    \"                else:\\n\",\n",
    "    \"                    ax = axes[j]\\n\",\n",
    "    \"                    \\n\",\n",
    "    \"                ax.imshow(img)\\n\",\n",
    "    \"                ax.set_title(f\\\"{category}\\\")\\n\",\n",
    "    \"                ax.axis('off')\\n\",\n",
    "    \"            except Exception as e:\\n\",\n",
    "    \"                print(f\\\"Error displaying image {img_info.get('filename')}: {e}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout(rect=[0, 0, 1, 0.96])\\n\",\n",
    "    \"    plt.savefig(FIGURES_PATH / f\\\"{title.lower().replace(' ', '_')}_samples.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import random module\\n\",\n",
    "    \"import random\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load and display sample images\\n\",\n",
    "    \"env_images, light_images = load_sample_images()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display environment samples\\n\",\n",
    "    \"display_sample_images(env_images, \\\"Environment Type\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display lighting condition samples\\n\",\n",
    "    \"display_sample_images(light_images, \\\"Lighting Condition\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Training Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load training results\\n\",\n",
    "    \"training_results_path = WEIGHTS_PATH / \\\"training_results.json\\\"\\n\",\n",
    "    \"if training_results_path.exists():\\n\",\n",
    "    \"    with open(training_results_path, 'r') as f:\\n\",\n",
    "    \"        training_results = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display training configuration\\n\",\n",
    "    \"    print(\\\"Training Configuration:\\\")\\n\",\n",
    "    \"    print(f\\\"Model: {training_results['model']['name']}\\\")\\n\",\n",
    "    \"    print(f\\\"Pretrained: {training_results['model']['pretrained']}\\\")\\n\",\n",
    "    \"    print(f\\\"Epochs: {training_results['training']['epochs']}\\\")\\n\",\n",
    "    \"    print(f\\\"Batch Size: {training_results['training']['batch_size']}\\\")\\n\",\n",
    "    \"    print(f\\\"Image Size: {training_results['training']['image_size']}\\\")\\n\",\n",
    "    \"    print(f\\\"Optimizer: {training_results['training']['optimizer']}\\\")\\n\",\n",
    "    \"    print(f\\\"Learning Rate: {training_results['training']['learning_rate']}\\\")\\n\",\n",
    "    \"    print(f\\\"Timestamp: {training_results['timestamp']}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Training results not found.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Training Curves\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize the training curves to analyze the model's training progress.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Try to find and load training history from YOLOv8 results directory\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    yolo_results_dir = Path(\\\"../runs/detect\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Find the latest results directory\\n\",\n",
    "    \"    result_dirs = list(yolo_results_dir.glob(\\\"synthetic_only*\\\"))\\n\",\n",
    "    \"    if result_dirs:\\n\",\n",
    "    \"        latest_dir = max(result_dirs, key=lambda p: p.stat().st_mtime)\\n\",\n",
    "    \"        results_csv = latest_dir / \\\"results.csv\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if results_csv.exists():\\n\",\n",
    "    \"            # Load results\\n\",\n",
    "    \"            train_df = pd.read_csv(results_csv)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Plot training curves\\n\",\n",
    "    \"            plt.figure(figsize=(12, 8))\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Plot losses\\n\",\n",
    "    \"            plt.subplot(2, 2, 1)\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['train/box_loss'], label='Train Box Loss')\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['val/box_loss'], label='Val Box Loss')\\n\",\n",
    "    \"            plt.title('Box Loss')\\n\",\n",
    "    \"            plt.xlabel('Epoch')\\n\",\n",
    "    \"            plt.ylabel('Loss')\\n\",\n",
    "    \"            plt.legend()\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.subplot(2, 2, 2)\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['train/cls_loss'], label='Train Cls Loss')\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['val/cls_loss'], label='Val Cls Loss')\\n\",\n",
    "    \"            plt.title('Class Loss')\\n\",\n",
    "    \"            plt.xlabel('Epoch')\\n\",\n",
    "    \"            plt.ylabel('Loss')\\n\",\n",
    "    \"            plt.legend()\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Plot metrics\\n\",\n",
    "    \"            plt.subplot(2, 2, 3)\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['metrics/precision'], label='Precision')\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['metrics/recall'], label='Recall')\\n\",\n",
    "    \"            plt.title('Precision and Recall')\\n\",\n",
    "    \"            plt.xlabel('Epoch')\\n\",\n",
    "    \"            plt.ylabel('Value')\\n\",\n",
    "    \"            plt.legend()\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.subplot(2, 2, 4)\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['metrics/mAP50'], label='mAP@0.5')\\n\",\n",
    "    \"            plt.plot(train_df['epoch'], train_df['metrics/mAP50-95'], label='mAP@0.5:0.95')\\n\",\n",
    "    \"            plt.title('mAP')\\n\",\n",
    "    \"            plt.xlabel('Epoch')\\n\",\n",
    "    \"            plt.ylabel('Value')\\n\",\n",
    "    \"            plt.legend()\\n\",\n",
    "    \"            plt.grid(True)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.tight_layout()\\n\",\n",
    "    \"            plt.savefig(FIGURES_PATH / \\\"training_curves.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"            plt.show()\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Display final metrics\\n\",\n",
    "    \"            final_metrics = train_df.iloc[-1]\\n\",\n",
    "    \"            print(f\\\"Final Training Metrics (Epoch {int(final_metrics['epoch'])})\\\")\\n\",\n",
    "    \"            print(f\\\"mAP@0.5: {final_metrics['metrics/mAP50']:.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"mAP@0.5:0.95: {final_metrics['metrics/mAP50-95']:.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"Precision: {final_metrics['metrics/precision']:.4f}\\\")\\n\",\n",
    "    \"            print(f\\\"Recall: {final_metrics['metrics/recall']:.4f}\\\")\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(\\\"Training results CSV not found.\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No YOLOv8 training results found.\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"Error loading training curves: {e}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Model Evaluation\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's analyze the evaluation results on the test set.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Load evaluation metrics\\n\",\n",
    "    \"eval_metrics_path = Path(\\\"../docs/evaluation/evaluation_metrics.json\\\")\\n\",\n",
    "    \"if eval_metrics_path.exists():\\n\",\n",
    "    \"    with open(eval_metrics_path, 'r') as f:\\n\",\n",
    "    \"        eval_metrics = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display overall metrics\\n\",\n",
    "    \"    overall = eval_metrics['overall']\\n\",\n",
    "    \"    print(\\\"Overall Evaluation Metrics:\\\")\\n\",\n",
    "    \"    print(f\\\"Precision: {overall['precision']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Recall: {overall['recall']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"mAP@0.5: {overall['mAP50']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"mAP@0.5:0.95: {overall['mAP50-95']:.4f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Display class metrics\\n\",\n",
    "    \"    if 'class' in eval_metrics:\\n\",\n",
    "    \"        class_metrics = pd.DataFrame(eval_metrics['class'])\\n\",\n",
    "    \"        display(class_metrics)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Plot class metrics\\n\",\n",
    "    \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"        plt.subplot(1, 2, 1)\\n\",\n",
    "    \"        sns.barplot(x='class_name', y='precision', data=class_metrics, color='skyblue')\\n\",\n",
    "    \"        plt.title('Precision by Class')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.ylim(0, 1.0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.subplot(1, 2, 2)\\n\",\n",
    "    \"        sns.barplot(x='class_name', y='recall', data=class_metrics, color='lightgreen')\\n\",\n",
    "    \"        plt.title('Recall by Class')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.ylim(0, 1.0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.savefig(FIGURES_PATH / \\\"precision_recall_by_class.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"        plt.subplot(1, 2, 1)\\n\",\n",
    "    \"        sns.barplot(x='class_name', y='mAP50', data=class_metrics, color='coral')\\n\",\n",
    "    \"        plt.title('mAP@0.5 by Class')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.ylim(0, 1.0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.subplot(1, 2, 2)\\n\",\n",
    "    \"        sns.barplot(x='class_name', y='mAP50-95', data=class_metrics, color='lightpink')\\n\",\n",
    "    \"        plt.title('mAP@0.5:0.95 by Class')\\n\",\n",
    "    \"        plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"        plt.ylim(0, 1.0)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        plt.tight_layout()\\n\",\n",
    "    \"        plt.savefig(FIGURES_PATH / \\\"map_by_class.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"        plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"Evaluation metrics not found.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Qualitative Detection Examples\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's visualize some example detections from the test set.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def load_detection_examples(num_samples=5):\\n\",\n",
    "    \"    \\\"\\\"\\\"Load sample detections from the test set.\\\"\\\"\\\"\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Find prediction directory (should be created by YOLOv8 val)\\n\",\n",
    "    \"        pred_dirs = list(Path(\\\"../runs/detect\\\").glob(\\\"val*\\\"))\\n\",\n",
    "    \"        if not pred_dirs:\\n\",\n",
    "    \"            print(\\\"No prediction results found.\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        latest_dir = max(pred_dirs, key=lambda p: p.stat().st_mtime)\\n\",\n",
    "    \"        pred_dir = latest_dir / \\\"predictions\\\"\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if not pred_dir.exists():\\n\",\n",
    "    \"            print(f\\\"Prediction directory not found: {pred_dir}\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Get prediction images\\n\",\n",
    "    \"        pred_images = list(pred_dir.glob(\\\"*.jpg\\\"))\\n\",\n",
    "    \"        if not pred_images:\\n\",\n",
    "    \"            print(\\\"No prediction images found.\\\")\\n\",\n",
    "    \"            return []\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Sample images\\n\",\n",
    "    \"        sample_images = random.sample(pred_images, min(num_samples, len(pred_images)))\\n\",\n",
    "    \"        return sample_images\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"Error loading detection examples: {e}\\\")\\n\",\n",
    "    \"        return []\\n\",\n",
    "    \"\\n\",\n",
    "    \"def display_detection_examples(image_paths):\\n\",\n",
    "    \"    \\\"\\\"\\\"Display detection examples.\\\"\\\"\\\"\\n\",\n",
    "    \"    if not image_paths:\\n\",\n",
    "    \"        print(\\\"No detection examples to display.\\\")\\n\",\n",
    "    \"        return\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    num_images = len(image_paths)\\n\",\n",
    "    \"    cols = min(3, num_images)\\n\",\n",
    "    \"    rows = (num_images + cols - 1) // cols\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(15, 5 * rows))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for i, img_path in enumerate(image_paths):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            img = cv2.imread(str(img_path))\\n\",\n",
    "    \"            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            plt.subplot(rows, cols, i + 1)\\n\",\n",
    "    \"            plt.imshow(img)\\n\",\n",
    "    \"            plt.title(f\\\"Detection Example {i+1}\\\")\\n\",\n",
    "    \"            plt.axis('off')\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print(f\\\"Error displaying detection image {img_path}: {e}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.savefig(FIGURES_PATH / \\\"detection_examples.png\\\", dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load and display detection examples\\n\",\n",
    "    \"detection_examples = load_detection_examples()\\n\",\n",
    "    \"display_detection_examples(detection_examples)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Analysis of Sim-to-Real Gap\\n\",\n",
    "    \"\\n\",\n",
    "    \"This section analyzes the strengths and weaknesses of the synthetic data approach and discusses the potential sim-to-real gap.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Strengths of Synthetic Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Controlled Data Generation**: Our synthetic pipeline allows precise control over environmental variables (lighting, weather, camera pose) that would be difficult to systematically capture in real-world data collection.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Perfect Ground Truth**: Synthetic data provides pixel-perfect ground truth annotations without the inconsistencies or errors that can occur with manual labeling.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Diverse Scenarios**: We can efficiently generate a wide variety of scenarios across different İstanbul environments that would require significant time and resources to collect manually.\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Rare Events**: We can generate scenes with unusual waste distributions or lighting conditions that might be rare in real-world data collection.\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. **Privacy Compliance**: Synthetic data eliminates privacy concerns that might arise when capturing real-world imagery in public spaces.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Weaknesses of Synthetic Data\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Realism Gap**: Despite our efforts to create realistic environments, there remains a gap between synthetic and real-world imagery in terms of texture details, lighting effects, and physics.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Limited Asset Diversity**: Our waste models, while diverse, still represent a subset of the full variety of waste types and appearances found in real environments.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Simplified Physics**: The placement and interaction of waste objects follows simplified physics models that may not perfectly match real-world scenarios.\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Environment Simplification**: Our simulated environments capture the essence of İstanbul locations but lack the full complexity and detail of real urban environments.\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. **Occlusion and Complex Scenes**: Real-world waste often appears in complex scenes with partial occlusion, varying states of degradation, and challenging contexts that are difficult to fully simulate.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Gap Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Based on our evaluation, the primary factors contributing to the sim-to-real gap include:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Texture and Material Realism**: Real waste items have complex textures, weathering, and deformation that are challenging to model synthetically.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Environmental Context**: Real environments have greater complexity in terms of background elements, ambient occlusion, and contextual placement of waste.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Lighting Complexity**: Real-world lighting includes subtle effects like inter-reflections, subsurface scattering, and atmospheric effects that are computationally expensive to simulate perfectly.\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Object Variation**: Real waste objects show greater variation in appearance, condition, and positioning than our synthetic models.\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. **Camera Effects**: Real drone cameras exhibit lens distortion, motion blur, and sensor noise characteristics that differ from our simulated camera.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusions and Future Work\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Conclusions\\n\",\n",
    "    \"\\n\",\n",
    "    \"Our synthetic data pipeline successfully generated a diverse and balanced dataset for training waste detection models in İstanbul's urban environments. The YOLOv8 detector trained on this synthetic data achieved promising results on the synthetic test set, with an overall mAP@0.5 of X.XX and mAP@0.5:0.95 of Y.YY.\\n\",\n",
    "    \"\\n\",\n",
    "    \"The analysis of the sim-to-real gap highlights both the strengths of our approach and areas for improvement. Despite limitations in perfect realism, the synthetic dataset provides valuable training data for object detection models, especially in scenarios where collecting and annotating real-world data would be challenging.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Future Work\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Domain Randomization**: Implement more aggressive domain randomization techniques to help the model generalize better to real-world conditions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Fine-tuning on Real Data**: Collect a small set of real-world drone imagery from İstanbul for fine-tuning the synthetic-trained model, potentially using the `finetune.py` script framework we've established.\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Improved Asset Quality**: Develop higher-fidelity 3D models of waste objects with more realistic textures, deformations, and weathering effects.\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Environmental Complexity**: Enhance the environmental models to include more detailed urban elements specific to İstanbul.\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. **Drone Camera Simulation**: Implement more realistic camera effects including motion blur, lens distortion, and sensor noise characteristics typical of drone cameras.\\n\",\n",
    "    \"\\n\",\n",
    "    \"6. **Seasonal Variations**: Extend the pipeline to include seasonal variations (snow, rain, autumn leaves) to improve robustness to different weather conditions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"7. **Real-world Validation**: Conduct a comprehensive real-world validation study using a drone with the trained model to quantitatively assess the sim-to-real gap.\\n\",\n",
    "    \"\\n\",\n",
    "    \"8. **Multi-modal Learning**: Explore multi-modal approaches that combine RGB imagery with depth or thermal information for more robust waste detection.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.10\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
